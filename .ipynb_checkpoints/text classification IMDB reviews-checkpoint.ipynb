{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division,print_function,unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb=keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The argument num_words=10000 keeps the top 10,000 most frequently occurring words in the training data.\n",
    "The rare words are discarded to keep the size of the data manageable.\n",
    "'''\n",
    "\n",
    "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "'''Let's take a moment to understand the format of the data. \n",
    "The dataset comes preprocessed: each example is an array of integers representing the words of the movie review. \n",
    "Each label is an integer value of either 0 or 1, where 0 is a negative review, \n",
    "and 1 is a positive review.'''\n",
    "\n",
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The text of reviews have been converted to integers, where each integer represents a specific word in a dictionary. \n",
    "Here's what the first review looks like:'''\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Movie reviews may be different lengths. The below code shows the number of words in the first and second reviews.\n",
    "Since inputs to a neural network must be the same length, we'll need to resolve this later.'''\n",
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''It may be useful to know how to convert integers back to text. \n",
    "Here, we'll create a helper function to query a dictionary object that contains the integer to string mapping:'''\n",
    "\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index={k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_word_index=dict([(v,k) for k,v in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reversed_word_index.get(i,'?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <UNK> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The reviews—the arrays of integers—must be converted to tensors before fed into the neural network. \n",
    "This conversion can be done a couple of ways:\n",
    "\n",
    "Convert the arrays into vectors of 0s and 1s indicating word occurrence, \n",
    "similar to a one-hot encoding. For example, the sequence [3, 5] would become a 10,000-dimensional vector that is all \n",
    "zeros except for indices 3 and 5, which are ones. Then, make this the first layer in our network—a Dense \n",
    "layer—that can handle floating point vector data. This approach is memory intensive, though, requiring a \n",
    "num_words * num_reviews size matrix.\n",
    "\n",
    "Alternatively, we can pad the arrays so they all have the same length, then create an integer tensor of shape \n",
    "max_length * num_reviews. We can use an embedding layer capable of handling this shape as the first layer in our network.\n",
    "\n",
    "In this tutorial, we will use the second approach.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the movie reviews must be the same length, we will use the pad_sequences function to standardize the lengths:\n",
    "\n",
    "train_data=keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                     value=word_index[\"<PAD>\"],\n",
    "                                                    padding=\"post\",\n",
    "                                                    maxlen=256)\n",
    "\n",
    "test_data=keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                     value=word_index[\"<PAD>\"],\n",
    "                                                    padding=\"post\",\n",
    "                                                    maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Build the model\n",
    "The neural network is created by stacking layers—this requires two main architectural decisions:\n",
    "\n",
    "How many layers to use in the model?\n",
    "How many hidden units to use for each layer?\n",
    "In this example, the input data consists of an array of word-indices. The labels to predict are either 0 or 1. Let's build a model for this problem:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "The first layer is an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding).\n",
    "Next, a GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "This fixed-length output vector is piped through a fully-connected (Dense) layer with 16 hidden units.\n",
    "The last layer is densely connected with a single output node. Using the sigmoid activation function, this value is a float between 0 and 1, representing a probability, or confidence level.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - ETA: 5s - loss: 0.6821 - acc: 0.744 - ETA: 4s - loss: 0.6818 - acc: 0.738 - ETA: 3s - loss: 0.6816 - acc: 0.733 - ETA: 3s - loss: 0.6815 - acc: 0.721 - ETA: 3s - loss: 0.6813 - acc: 0.721 - ETA: 2s - loss: 0.6810 - acc: 0.721 - ETA: 2s - loss: 0.6807 - acc: 0.724 - ETA: 2s - loss: 0.6806 - acc: 0.722 - ETA: 2s - loss: 0.6805 - acc: 0.719 - ETA: 2s - loss: 0.6802 - acc: 0.723 - ETA: 1s - loss: 0.6801 - acc: 0.724 - ETA: 1s - loss: 0.6798 - acc: 0.726 - ETA: 1s - loss: 0.6797 - acc: 0.724 - ETA: 1s - loss: 0.6794 - acc: 0.726 - ETA: 1s - loss: 0.6793 - acc: 0.726 - ETA: 1s - loss: 0.6791 - acc: 0.729 - ETA: 1s - loss: 0.6789 - acc: 0.730 - ETA: 1s - loss: 0.6785 - acc: 0.733 - ETA: 1s - loss: 0.6781 - acc: 0.735 - ETA: 0s - loss: 0.6780 - acc: 0.734 - ETA: 0s - loss: 0.6777 - acc: 0.734 - ETA: 0s - loss: 0.6776 - acc: 0.734 - ETA: 0s - loss: 0.6772 - acc: 0.736 - ETA: 0s - loss: 0.6770 - acc: 0.735 - ETA: 0s - loss: 0.6768 - acc: 0.735 - ETA: 0s - loss: 0.6764 - acc: 0.738 - ETA: 0s - loss: 0.6762 - acc: 0.739 - ETA: 0s - loss: 0.6757 - acc: 0.741 - ETA: 0s - loss: 0.6754 - acc: 0.742 - 3s 221us/sample - loss: 0.6753 - acc: 0.7424 - val_loss: 0.6678 - val_acc: 0.7450\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.6639 - acc: 0.759 - ETA: 2s - loss: 0.6642 - acc: 0.770 - ETA: 2s - loss: 0.6642 - acc: 0.770 - ETA: 2s - loss: 0.6642 - acc: 0.772 - ETA: 2s - loss: 0.6634 - acc: 0.769 - ETA: 2s - loss: 0.6632 - acc: 0.767 - ETA: 2s - loss: 0.6631 - acc: 0.762 - ETA: 1s - loss: 0.6623 - acc: 0.763 - ETA: 1s - loss: 0.6622 - acc: 0.761 - ETA: 1s - loss: 0.6617 - acc: 0.755 - ETA: 1s - loss: 0.6616 - acc: 0.752 - ETA: 1s - loss: 0.6614 - acc: 0.748 - ETA: 1s - loss: 0.6612 - acc: 0.746 - ETA: 1s - loss: 0.6607 - acc: 0.748 - ETA: 1s - loss: 0.6603 - acc: 0.748 - ETA: 1s - loss: 0.6596 - acc: 0.751 - ETA: 1s - loss: 0.6593 - acc: 0.751 - ETA: 1s - loss: 0.6590 - acc: 0.750 - ETA: 0s - loss: 0.6586 - acc: 0.751 - ETA: 0s - loss: 0.6581 - acc: 0.752 - ETA: 0s - loss: 0.6575 - acc: 0.753 - ETA: 0s - loss: 0.6571 - acc: 0.753 - ETA: 0s - loss: 0.6565 - acc: 0.755 - ETA: 0s - loss: 0.6558 - acc: 0.756 - ETA: 0s - loss: 0.6554 - acc: 0.757 - ETA: 0s - loss: 0.6548 - acc: 0.758 - ETA: 0s - loss: 0.6542 - acc: 0.759 - ETA: 0s - loss: 0.6537 - acc: 0.760 - ETA: 0s - loss: 0.6533 - acc: 0.760 - 3s 200us/sample - loss: 0.6531 - acc: 0.7603 - val_loss: 0.6415 - val_acc: 0.7520\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.6375 - acc: 0.771 - ETA: 2s - loss: 0.6365 - acc: 0.758 - ETA: 2s - loss: 0.6356 - acc: 0.768 - ETA: 2s - loss: 0.6345 - acc: 0.772 - ETA: 2s - loss: 0.6338 - acc: 0.773 - ETA: 2s - loss: 0.6334 - acc: 0.773 - ETA: 2s - loss: 0.6333 - acc: 0.775 - ETA: 1s - loss: 0.6330 - acc: 0.778 - ETA: 1s - loss: 0.6332 - acc: 0.775 - ETA: 1s - loss: 0.6321 - acc: 0.779 - ETA: 1s - loss: 0.6315 - acc: 0.782 - ETA: 1s - loss: 0.6311 - acc: 0.781 - ETA: 1s - loss: 0.6305 - acc: 0.780 - ETA: 1s - loss: 0.6301 - acc: 0.780 - ETA: 1s - loss: 0.6293 - acc: 0.781 - ETA: 1s - loss: 0.6289 - acc: 0.782 - ETA: 1s - loss: 0.6281 - acc: 0.784 - ETA: 1s - loss: 0.6274 - acc: 0.785 - ETA: 1s - loss: 0.6266 - acc: 0.786 - ETA: 0s - loss: 0.6261 - acc: 0.786 - ETA: 0s - loss: 0.6255 - acc: 0.787 - ETA: 0s - loss: 0.6247 - acc: 0.787 - ETA: 0s - loss: 0.6240 - acc: 0.787 - ETA: 0s - loss: 0.6231 - acc: 0.787 - ETA: 0s - loss: 0.6224 - acc: 0.788 - ETA: 0s - loss: 0.6216 - acc: 0.787 - ETA: 0s - loss: 0.6210 - acc: 0.787 - ETA: 0s - loss: 0.6204 - acc: 0.788 - ETA: 0s - loss: 0.6195 - acc: 0.788 - 3s 218us/sample - loss: 0.6193 - acc: 0.7891 - val_loss: 0.6062 - val_acc: 0.7805\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.5869 - acc: 0.830 - ETA: 2s - loss: 0.5937 - acc: 0.812 - ETA: 2s - loss: 0.5934 - acc: 0.809 - ETA: 2s - loss: 0.5928 - acc: 0.811 - ETA: 2s - loss: 0.5941 - acc: 0.807 - ETA: 2s - loss: 0.5930 - acc: 0.809 - ETA: 2s - loss: 0.5925 - acc: 0.808 - ETA: 1s - loss: 0.5919 - acc: 0.807 - ETA: 1s - loss: 0.5917 - acc: 0.806 - ETA: 1s - loss: 0.5908 - acc: 0.805 - ETA: 1s - loss: 0.5896 - acc: 0.807 - ETA: 1s - loss: 0.5892 - acc: 0.805 - ETA: 1s - loss: 0.5879 - acc: 0.806 - ETA: 1s - loss: 0.5873 - acc: 0.806 - ETA: 1s - loss: 0.5871 - acc: 0.804 - ETA: 1s - loss: 0.5870 - acc: 0.803 - ETA: 1s - loss: 0.5865 - acc: 0.804 - ETA: 1s - loss: 0.5858 - acc: 0.804 - ETA: 0s - loss: 0.5850 - acc: 0.804 - ETA: 0s - loss: 0.5839 - acc: 0.805 - ETA: 0s - loss: 0.5831 - acc: 0.807 - ETA: 0s - loss: 0.5825 - acc: 0.807 - ETA: 0s - loss: 0.5814 - acc: 0.808 - ETA: 0s - loss: 0.5808 - acc: 0.809 - ETA: 0s - loss: 0.5803 - acc: 0.809 - ETA: 0s - loss: 0.5796 - acc: 0.809 - ETA: 0s - loss: 0.5790 - acc: 0.809 - ETA: 0s - loss: 0.5784 - acc: 0.809 - ETA: 0s - loss: 0.5772 - acc: 0.809 - 3s 219us/sample - loss: 0.5768 - acc: 0.8099 - val_loss: 0.5654 - val_acc: 0.8017\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.5668 - acc: 0.798 - ETA: 2s - loss: 0.5574 - acc: 0.823 - ETA: 2s - loss: 0.5494 - acc: 0.833 - ETA: 2s - loss: 0.5464 - acc: 0.838 - ETA: 2s - loss: 0.5488 - acc: 0.834 - ETA: 2s - loss: 0.5502 - acc: 0.830 - ETA: 2s - loss: 0.5493 - acc: 0.826 - ETA: 2s - loss: 0.5473 - acc: 0.826 - ETA: 2s - loss: 0.5457 - acc: 0.827 - ETA: 2s - loss: 0.5453 - acc: 0.827 - ETA: 2s - loss: 0.5448 - acc: 0.825 - ETA: 1s - loss: 0.5445 - acc: 0.823 - ETA: 1s - loss: 0.5434 - acc: 0.823 - ETA: 1s - loss: 0.5429 - acc: 0.821 - ETA: 1s - loss: 0.5423 - acc: 0.822 - ETA: 1s - loss: 0.5419 - acc: 0.822 - ETA: 1s - loss: 0.5405 - acc: 0.824 - ETA: 1s - loss: 0.5394 - acc: 0.824 - ETA: 1s - loss: 0.5382 - acc: 0.824 - ETA: 0s - loss: 0.5370 - acc: 0.824 - ETA: 0s - loss: 0.5357 - acc: 0.825 - ETA: 0s - loss: 0.5350 - acc: 0.825 - ETA: 0s - loss: 0.5339 - acc: 0.825 - ETA: 0s - loss: 0.5327 - acc: 0.826 - ETA: 0s - loss: 0.5321 - acc: 0.826 - ETA: 0s - loss: 0.5321 - acc: 0.825 - ETA: 0s - loss: 0.5313 - acc: 0.826 - ETA: 0s - loss: 0.5307 - acc: 0.825 - ETA: 0s - loss: 0.5296 - acc: 0.826 - 3s 225us/sample - loss: 0.5297 - acc: 0.8258 - val_loss: 0.5215 - val_acc: 0.8178\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.5056 - acc: 0.818 - ETA: 2s - loss: 0.5048 - acc: 0.830 - ETA: 2s - loss: 0.4975 - acc: 0.834 - ETA: 2s - loss: 0.4957 - acc: 0.838 - ETA: 2s - loss: 0.4970 - acc: 0.835 - ETA: 2s - loss: 0.4966 - acc: 0.836 - ETA: 1s - loss: 0.4997 - acc: 0.833 - ETA: 1s - loss: 0.4996 - acc: 0.834 - ETA: 1s - loss: 0.4973 - acc: 0.838 - ETA: 1s - loss: 0.4972 - acc: 0.837 - ETA: 1s - loss: 0.4965 - acc: 0.837 - ETA: 1s - loss: 0.4951 - acc: 0.838 - ETA: 1s - loss: 0.4945 - acc: 0.838 - ETA: 1s - loss: 0.4946 - acc: 0.838 - ETA: 1s - loss: 0.4928 - acc: 0.840 - ETA: 1s - loss: 0.4920 - acc: 0.840 - ETA: 1s - loss: 0.4918 - acc: 0.840 - ETA: 0s - loss: 0.4911 - acc: 0.840 - ETA: 0s - loss: 0.4900 - acc: 0.841 - ETA: 0s - loss: 0.4892 - acc: 0.841 - ETA: 0s - loss: 0.4887 - acc: 0.842 - ETA: 0s - loss: 0.4881 - acc: 0.842 - ETA: 0s - loss: 0.4873 - acc: 0.842 - ETA: 0s - loss: 0.4864 - acc: 0.842 - ETA: 0s - loss: 0.4856 - acc: 0.842 - ETA: 0s - loss: 0.4847 - acc: 0.843 - ETA: 0s - loss: 0.4845 - acc: 0.844 - ETA: 0s - loss: 0.4843 - acc: 0.843 - ETA: 0s - loss: 0.4832 - acc: 0.844 - 3s 195us/sample - loss: 0.4829 - acc: 0.8445 - val_loss: 0.4810 - val_acc: 0.8320\n",
      "Epoch 7/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - ETA: 2s - loss: 0.4534 - acc: 0.861 - ETA: 2s - loss: 0.4578 - acc: 0.854 - ETA: 2s - loss: 0.4548 - acc: 0.853 - ETA: 2s - loss: 0.4539 - acc: 0.855 - ETA: 2s - loss: 0.4500 - acc: 0.862 - ETA: 2s - loss: 0.4494 - acc: 0.862 - ETA: 2s - loss: 0.4501 - acc: 0.860 - ETA: 2s - loss: 0.4496 - acc: 0.860 - ETA: 1s - loss: 0.4502 - acc: 0.860 - ETA: 1s - loss: 0.4495 - acc: 0.859 - ETA: 1s - loss: 0.4488 - acc: 0.859 - ETA: 1s - loss: 0.4489 - acc: 0.858 - ETA: 1s - loss: 0.4489 - acc: 0.857 - ETA: 1s - loss: 0.4495 - acc: 0.856 - ETA: 1s - loss: 0.4479 - acc: 0.856 - ETA: 1s - loss: 0.4466 - acc: 0.856 - ETA: 1s - loss: 0.4459 - acc: 0.857 - ETA: 1s - loss: 0.4450 - acc: 0.856 - ETA: 0s - loss: 0.4440 - acc: 0.857 - ETA: 0s - loss: 0.4434 - acc: 0.856 - ETA: 0s - loss: 0.4429 - acc: 0.857 - ETA: 0s - loss: 0.4432 - acc: 0.856 - ETA: 0s - loss: 0.4428 - acc: 0.856 - ETA: 0s - loss: 0.4425 - acc: 0.857 - ETA: 0s - loss: 0.4407 - acc: 0.858 - ETA: 0s - loss: 0.4407 - acc: 0.858 - ETA: 0s - loss: 0.4401 - acc: 0.858 - ETA: 0s - loss: 0.4398 - acc: 0.858 - ETA: 0s - loss: 0.4398 - acc: 0.858 - 3s 215us/sample - loss: 0.4394 - acc: 0.8591 - val_loss: 0.4445 - val_acc: 0.8431\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.4168 - acc: 0.882 - ETA: 3s - loss: 0.4129 - acc: 0.882 - ETA: 2s - loss: 0.4139 - acc: 0.876 - ETA: 2s - loss: 0.4107 - acc: 0.875 - ETA: 2s - loss: 0.4144 - acc: 0.868 - ETA: 2s - loss: 0.4168 - acc: 0.866 - ETA: 2s - loss: 0.4144 - acc: 0.868 - ETA: 2s - loss: 0.4134 - acc: 0.868 - ETA: 2s - loss: 0.4135 - acc: 0.868 - ETA: 1s - loss: 0.4130 - acc: 0.869 - ETA: 1s - loss: 0.4122 - acc: 0.870 - ETA: 1s - loss: 0.4106 - acc: 0.870 - ETA: 1s - loss: 0.4092 - acc: 0.871 - ETA: 1s - loss: 0.4095 - acc: 0.870 - ETA: 1s - loss: 0.4080 - acc: 0.870 - ETA: 1s - loss: 0.4078 - acc: 0.870 - ETA: 1s - loss: 0.4077 - acc: 0.870 - ETA: 1s - loss: 0.4082 - acc: 0.869 - ETA: 1s - loss: 0.4078 - acc: 0.869 - ETA: 0s - loss: 0.4067 - acc: 0.870 - ETA: 0s - loss: 0.4058 - acc: 0.870 - ETA: 0s - loss: 0.4061 - acc: 0.870 - ETA: 0s - loss: 0.4053 - acc: 0.870 - ETA: 0s - loss: 0.4043 - acc: 0.870 - ETA: 0s - loss: 0.4039 - acc: 0.870 - ETA: 0s - loss: 0.4034 - acc: 0.870 - ETA: 0s - loss: 0.4024 - acc: 0.871 - ETA: 0s - loss: 0.4023 - acc: 0.871 - ETA: 0s - loss: 0.4014 - acc: 0.871 - 3s 212us/sample - loss: 0.4010 - acc: 0.8723 - val_loss: 0.4143 - val_acc: 0.8501\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.3706 - acc: 0.890 - ETA: 2s - loss: 0.3791 - acc: 0.871 - ETA: 2s - loss: 0.3804 - acc: 0.873 - ETA: 2s - loss: 0.3795 - acc: 0.873 - ETA: 2s - loss: 0.3816 - acc: 0.872 - ETA: 2s - loss: 0.3809 - acc: 0.872 - ETA: 2s - loss: 0.3799 - acc: 0.874 - ETA: 1s - loss: 0.3803 - acc: 0.876 - ETA: 1s - loss: 0.3789 - acc: 0.877 - ETA: 1s - loss: 0.3771 - acc: 0.878 - ETA: 1s - loss: 0.3778 - acc: 0.878 - ETA: 1s - loss: 0.3758 - acc: 0.879 - ETA: 1s - loss: 0.3765 - acc: 0.879 - ETA: 1s - loss: 0.3759 - acc: 0.879 - ETA: 1s - loss: 0.3759 - acc: 0.878 - ETA: 1s - loss: 0.3767 - acc: 0.877 - ETA: 1s - loss: 0.3749 - acc: 0.878 - ETA: 1s - loss: 0.3752 - acc: 0.877 - ETA: 0s - loss: 0.3752 - acc: 0.877 - ETA: 0s - loss: 0.3753 - acc: 0.877 - ETA: 0s - loss: 0.3733 - acc: 0.878 - ETA: 0s - loss: 0.3731 - acc: 0.878 - ETA: 0s - loss: 0.3723 - acc: 0.878 - ETA: 0s - loss: 0.3718 - acc: 0.878 - ETA: 0s - loss: 0.3708 - acc: 0.879 - ETA: 0s - loss: 0.3704 - acc: 0.879 - ETA: 0s - loss: 0.3701 - acc: 0.879 - ETA: 0s - loss: 0.3694 - acc: 0.879 - ETA: 0s - loss: 0.3684 - acc: 0.880 - 3s 201us/sample - loss: 0.3685 - acc: 0.8801 - val_loss: 0.3892 - val_acc: 0.8584\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.3455 - acc: 0.892 - ETA: 2s - loss: 0.3555 - acc: 0.886 - ETA: 2s - loss: 0.3598 - acc: 0.882 - ETA: 2s - loss: 0.3583 - acc: 0.882 - ETA: 1s - loss: 0.3589 - acc: 0.882 - ETA: 1s - loss: 0.3566 - acc: 0.882 - ETA: 1s - loss: 0.3531 - acc: 0.885 - ETA: 1s - loss: 0.3499 - acc: 0.886 - ETA: 1s - loss: 0.3505 - acc: 0.885 - ETA: 1s - loss: 0.3511 - acc: 0.884 - ETA: 1s - loss: 0.3507 - acc: 0.884 - ETA: 1s - loss: 0.3501 - acc: 0.885 - ETA: 1s - loss: 0.3499 - acc: 0.887 - ETA: 1s - loss: 0.3501 - acc: 0.888 - ETA: 1s - loss: 0.3486 - acc: 0.888 - ETA: 1s - loss: 0.3480 - acc: 0.887 - ETA: 1s - loss: 0.3481 - acc: 0.886 - ETA: 0s - loss: 0.3466 - acc: 0.886 - ETA: 0s - loss: 0.3456 - acc: 0.887 - ETA: 0s - loss: 0.3448 - acc: 0.888 - ETA: 0s - loss: 0.3443 - acc: 0.888 - ETA: 0s - loss: 0.3440 - acc: 0.888 - ETA: 0s - loss: 0.3435 - acc: 0.888 - ETA: 0s - loss: 0.3428 - acc: 0.888 - ETA: 0s - loss: 0.3430 - acc: 0.888 - ETA: 0s - loss: 0.3418 - acc: 0.888 - ETA: 0s - loss: 0.3411 - acc: 0.888 - ETA: 0s - loss: 0.3409 - acc: 0.889 - ETA: 0s - loss: 0.3412 - acc: 0.888 - 3s 179us/sample - loss: 0.3409 - acc: 0.8886 - val_loss: 0.3698 - val_acc: 0.8609\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - ETA: 3s - loss: 0.3161 - acc: 0.896 - ETA: 3s - loss: 0.3210 - acc: 0.890 - ETA: 2s - loss: 0.3172 - acc: 0.890 - ETA: 2s - loss: 0.3174 - acc: 0.895 - ETA: 2s - loss: 0.3215 - acc: 0.890 - ETA: 2s - loss: 0.3207 - acc: 0.891 - ETA: 2s - loss: 0.3182 - acc: 0.891 - ETA: 2s - loss: 0.3165 - acc: 0.893 - ETA: 2s - loss: 0.3169 - acc: 0.892 - ETA: 1s - loss: 0.3190 - acc: 0.891 - ETA: 1s - loss: 0.3207 - acc: 0.891 - ETA: 1s - loss: 0.3221 - acc: 0.891 - ETA: 1s - loss: 0.3197 - acc: 0.893 - ETA: 1s - loss: 0.3190 - acc: 0.894 - ETA: 1s - loss: 0.3188 - acc: 0.894 - ETA: 1s - loss: 0.3188 - acc: 0.895 - ETA: 1s - loss: 0.3194 - acc: 0.895 - ETA: 1s - loss: 0.3185 - acc: 0.896 - ETA: 1s - loss: 0.3185 - acc: 0.896 - ETA: 0s - loss: 0.3175 - acc: 0.896 - ETA: 0s - loss: 0.3175 - acc: 0.896 - ETA: 0s - loss: 0.3185 - acc: 0.895 - ETA: 0s - loss: 0.3183 - acc: 0.895 - ETA: 0s - loss: 0.3174 - acc: 0.895 - ETA: 0s - loss: 0.3172 - acc: 0.895 - ETA: 0s - loss: 0.3171 - acc: 0.895 - ETA: 0s - loss: 0.3176 - acc: 0.894 - ETA: 0s - loss: 0.3174 - acc: 0.894 - ETA: 0s - loss: 0.3179 - acc: 0.894 - 3s 217us/sample - loss: 0.3183 - acc: 0.8936 - val_loss: 0.3525 - val_acc: 0.8684\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.3022 - acc: 0.906 - ETA: 3s - loss: 0.3023 - acc: 0.904 - ETA: 2s - loss: 0.3056 - acc: 0.901 - ETA: 2s - loss: 0.3043 - acc: 0.902 - ETA: 2s - loss: 0.3033 - acc: 0.901 - ETA: 2s - loss: 0.3040 - acc: 0.897 - ETA: 2s - loss: 0.3033 - acc: 0.899 - ETA: 2s - loss: 0.3023 - acc: 0.898 - ETA: 2s - loss: 0.3037 - acc: 0.898 - ETA: 1s - loss: 0.3045 - acc: 0.896 - ETA: 1s - loss: 0.3024 - acc: 0.897 - ETA: 1s - loss: 0.3036 - acc: 0.897 - ETA: 1s - loss: 0.3032 - acc: 0.897 - ETA: 1s - loss: 0.3022 - acc: 0.897 - ETA: 1s - loss: 0.3015 - acc: 0.898 - ETA: 1s - loss: 0.3010 - acc: 0.897 - ETA: 1s - loss: 0.3003 - acc: 0.898 - ETA: 1s - loss: 0.2999 - acc: 0.898 - ETA: 0s - loss: 0.2998 - acc: 0.898 - ETA: 0s - loss: 0.2980 - acc: 0.900 - ETA: 0s - loss: 0.2978 - acc: 0.899 - ETA: 0s - loss: 0.2980 - acc: 0.899 - ETA: 0s - loss: 0.2983 - acc: 0.899 - ETA: 0s - loss: 0.2983 - acc: 0.899 - ETA: 0s - loss: 0.2981 - acc: 0.899 - ETA: 0s - loss: 0.2984 - acc: 0.898 - ETA: 0s - loss: 0.2977 - acc: 0.899 - ETA: 0s - loss: 0.2975 - acc: 0.899 - ETA: 0s - loss: 0.2977 - acc: 0.899 - 3s 200us/sample - loss: 0.2979 - acc: 0.8991 - val_loss: 0.3399 - val_acc: 0.8715\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - ETA: 2s - loss: 0.2935 - acc: 0.912 - ETA: 2s - loss: 0.2980 - acc: 0.899 - ETA: 2s - loss: 0.2951 - acc: 0.899 - ETA: 2s - loss: 0.2951 - acc: 0.900 - ETA: 2s - loss: 0.2937 - acc: 0.900 - ETA: 2s - loss: 0.2898 - acc: 0.902 - ETA: 2s - loss: 0.2878 - acc: 0.903 - ETA: 1s - loss: 0.2871 - acc: 0.903 - ETA: 1s - loss: 0.2844 - acc: 0.904 - ETA: 1s - loss: 0.2856 - acc: 0.901 - ETA: 1s - loss: 0.2864 - acc: 0.901 - ETA: 1s - loss: 0.2848 - acc: 0.901 - ETA: 1s - loss: 0.2842 - acc: 0.901 - ETA: 1s - loss: 0.2851 - acc: 0.900 - ETA: 1s - loss: 0.2857 - acc: 0.900 - ETA: 1s - loss: 0.2863 - acc: 0.899 - ETA: 1s - loss: 0.2863 - acc: 0.899 - ETA: 1s - loss: 0.2868 - acc: 0.899 - ETA: 1s - loss: 0.2869 - acc: 0.899 - ETA: 0s - loss: 0.2859 - acc: 0.899 - ETA: 0s - loss: 0.2857 - acc: 0.900 - ETA: 0s - loss: 0.2845 - acc: 0.901 - ETA: 0s - loss: 0.2850 - acc: 0.900 - ETA: 0s - loss: 0.2840 - acc: 0.901 - ETA: 0s - loss: 0.2836 - acc: 0.902 - ETA: 0s - loss: 0.2831 - acc: 0.902 - ETA: 0s - loss: 0.2827 - acc: 0.903 - ETA: 0s - loss: 0.2818 - acc: 0.903 - ETA: 0s - loss: 0.2811 - acc: 0.903 - 3s 200us/sample - loss: 0.2809 - acc: 0.9037 - val_loss: 0.3294 - val_acc: 0.8730\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.2873 - acc: 0.890 - ETA: 2s - loss: 0.2892 - acc: 0.890 - ETA: 2s - loss: 0.2860 - acc: 0.895 - ETA: 2s - loss: 0.2851 - acc: 0.895 - ETA: 2s - loss: 0.2780 - acc: 0.902 - ETA: 2s - loss: 0.2767 - acc: 0.902 - ETA: 1s - loss: 0.2743 - acc: 0.902 - ETA: 1s - loss: 0.2725 - acc: 0.902 - ETA: 1s - loss: 0.2728 - acc: 0.903 - ETA: 1s - loss: 0.2713 - acc: 0.906 - ETA: 1s - loss: 0.2698 - acc: 0.907 - ETA: 1s - loss: 0.2715 - acc: 0.906 - ETA: 1s - loss: 0.2679 - acc: 0.908 - ETA: 1s - loss: 0.2671 - acc: 0.908 - ETA: 1s - loss: 0.2669 - acc: 0.909 - ETA: 1s - loss: 0.2660 - acc: 0.908 - ETA: 1s - loss: 0.2663 - acc: 0.908 - ETA: 1s - loss: 0.2650 - acc: 0.909 - ETA: 0s - loss: 0.2648 - acc: 0.908 - ETA: 0s - loss: 0.2642 - acc: 0.909 - ETA: 0s - loss: 0.2648 - acc: 0.909 - ETA: 0s - loss: 0.2657 - acc: 0.908 - ETA: 0s - loss: 0.2657 - acc: 0.908 - ETA: 0s - loss: 0.2654 - acc: 0.908 - ETA: 0s - loss: 0.2652 - acc: 0.909 - ETA: 0s - loss: 0.2642 - acc: 0.909 - ETA: 0s - loss: 0.2651 - acc: 0.909 - ETA: 0s - loss: 0.2660 - acc: 0.908 - ETA: 0s - loss: 0.2662 - acc: 0.908 - 3s 207us/sample - loss: 0.2656 - acc: 0.9085 - val_loss: 0.3206 - val_acc: 0.8744\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.2595 - acc: 0.900 - ETA: 2s - loss: 0.2705 - acc: 0.887 - ETA: 2s - loss: 0.2733 - acc: 0.893 - ETA: 2s - loss: 0.2623 - acc: 0.902 - ETA: 2s - loss: 0.2589 - acc: 0.907 - ETA: 2s - loss: 0.2613 - acc: 0.906 - ETA: 1s - loss: 0.2586 - acc: 0.908 - ETA: 1s - loss: 0.2553 - acc: 0.910 - ETA: 1s - loss: 0.2582 - acc: 0.908 - ETA: 1s - loss: 0.2563 - acc: 0.911 - ETA: 1s - loss: 0.2586 - acc: 0.910 - ETA: 1s - loss: 0.2573 - acc: 0.910 - ETA: 1s - loss: 0.2580 - acc: 0.910 - ETA: 1s - loss: 0.2574 - acc: 0.910 - ETA: 1s - loss: 0.2569 - acc: 0.911 - ETA: 1s - loss: 0.2568 - acc: 0.911 - ETA: 1s - loss: 0.2562 - acc: 0.911 - ETA: 1s - loss: 0.2557 - acc: 0.911 - ETA: 0s - loss: 0.2547 - acc: 0.911 - ETA: 0s - loss: 0.2553 - acc: 0.910 - ETA: 0s - loss: 0.2547 - acc: 0.911 - ETA: 0s - loss: 0.2543 - acc: 0.912 - ETA: 0s - loss: 0.2543 - acc: 0.911 - ETA: 0s - loss: 0.2538 - acc: 0.912 - ETA: 0s - loss: 0.2533 - acc: 0.912 - ETA: 0s - loss: 0.2528 - acc: 0.912 - ETA: 0s - loss: 0.2527 - acc: 0.912 - ETA: 0s - loss: 0.2522 - acc: 0.912 - ETA: 0s - loss: 0.2520 - acc: 0.913 - 3s 195us/sample - loss: 0.2516 - acc: 0.9135 - val_loss: 0.3132 - val_acc: 0.8769\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - ETA: 3s - loss: 0.2232 - acc: 0.939 - ETA: 3s - loss: 0.2222 - acc: 0.933 - ETA: 2s - loss: 0.2329 - acc: 0.921 - ETA: 2s - loss: 0.2359 - acc: 0.920 - ETA: 2s - loss: 0.2408 - acc: 0.919 - ETA: 2s - loss: 0.2417 - acc: 0.918 - ETA: 2s - loss: 0.2423 - acc: 0.917 - ETA: 2s - loss: 0.2421 - acc: 0.919 - ETA: 1s - loss: 0.2397 - acc: 0.920 - ETA: 1s - loss: 0.2401 - acc: 0.918 - ETA: 1s - loss: 0.2405 - acc: 0.917 - ETA: 1s - loss: 0.2404 - acc: 0.916 - ETA: 1s - loss: 0.2390 - acc: 0.918 - ETA: 1s - loss: 0.2400 - acc: 0.917 - ETA: 1s - loss: 0.2391 - acc: 0.918 - ETA: 1s - loss: 0.2396 - acc: 0.918 - ETA: 1s - loss: 0.2396 - acc: 0.918 - ETA: 1s - loss: 0.2400 - acc: 0.918 - ETA: 0s - loss: 0.2417 - acc: 0.916 - ETA: 0s - loss: 0.2411 - acc: 0.917 - ETA: 0s - loss: 0.2412 - acc: 0.917 - ETA: 0s - loss: 0.2407 - acc: 0.916 - ETA: 0s - loss: 0.2412 - acc: 0.916 - ETA: 0s - loss: 0.2407 - acc: 0.916 - ETA: 0s - loss: 0.2407 - acc: 0.917 - ETA: 0s - loss: 0.2398 - acc: 0.917 - ETA: 0s - loss: 0.2394 - acc: 0.918 - ETA: 0s - loss: 0.2399 - acc: 0.917 - ETA: 0s - loss: 0.2392 - acc: 0.918 - 3s 191us/sample - loss: 0.2391 - acc: 0.9182 - val_loss: 0.3068 - val_acc: 0.8803\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.2323 - acc: 0.925 - ETA: 2s - loss: 0.2350 - acc: 0.922 - ETA: 2s - loss: 0.2326 - acc: 0.922 - ETA: 2s - loss: 0.2315 - acc: 0.919 - ETA: 2s - loss: 0.2365 - acc: 0.917 - ETA: 2s - loss: 0.2327 - acc: 0.918 - ETA: 2s - loss: 0.2341 - acc: 0.919 - ETA: 1s - loss: 0.2353 - acc: 0.919 - ETA: 1s - loss: 0.2365 - acc: 0.917 - ETA: 1s - loss: 0.2325 - acc: 0.918 - ETA: 1s - loss: 0.2303 - acc: 0.921 - ETA: 1s - loss: 0.2285 - acc: 0.921 - ETA: 1s - loss: 0.2273 - acc: 0.921 - ETA: 1s - loss: 0.2273 - acc: 0.921 - ETA: 1s - loss: 0.2277 - acc: 0.920 - ETA: 1s - loss: 0.2291 - acc: 0.920 - ETA: 1s - loss: 0.2295 - acc: 0.920 - ETA: 0s - loss: 0.2268 - acc: 0.921 - ETA: 0s - loss: 0.2262 - acc: 0.921 - ETA: 0s - loss: 0.2253 - acc: 0.922 - ETA: 0s - loss: 0.2259 - acc: 0.922 - ETA: 0s - loss: 0.2270 - acc: 0.921 - ETA: 0s - loss: 0.2270 - acc: 0.922 - ETA: 0s - loss: 0.2272 - acc: 0.921 - ETA: 0s - loss: 0.2274 - acc: 0.921 - ETA: 0s - loss: 0.2280 - acc: 0.920 - ETA: 0s - loss: 0.2284 - acc: 0.920 - ETA: 0s - loss: 0.2288 - acc: 0.919 - ETA: 0s - loss: 0.2280 - acc: 0.920 - 3s 189us/sample - loss: 0.2278 - acc: 0.9208 - val_loss: 0.3014 - val_acc: 0.8805\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.2210 - acc: 0.918 - ETA: 2s - loss: 0.2204 - acc: 0.921 - ETA: 2s - loss: 0.2203 - acc: 0.921 - ETA: 2s - loss: 0.2209 - acc: 0.923 - ETA: 2s - loss: 0.2214 - acc: 0.925 - ETA: 2s - loss: 0.2226 - acc: 0.923 - ETA: 2s - loss: 0.2207 - acc: 0.922 - ETA: 2s - loss: 0.2238 - acc: 0.919 - ETA: 1s - loss: 0.2247 - acc: 0.918 - ETA: 1s - loss: 0.2231 - acc: 0.918 - ETA: 1s - loss: 0.2217 - acc: 0.919 - ETA: 1s - loss: 0.2208 - acc: 0.920 - ETA: 1s - loss: 0.2206 - acc: 0.921 - ETA: 1s - loss: 0.2204 - acc: 0.921 - ETA: 1s - loss: 0.2201 - acc: 0.921 - ETA: 1s - loss: 0.2192 - acc: 0.922 - ETA: 1s - loss: 0.2172 - acc: 0.924 - ETA: 1s - loss: 0.2160 - acc: 0.925 - ETA: 0s - loss: 0.2172 - acc: 0.924 - ETA: 0s - loss: 0.2173 - acc: 0.924 - ETA: 0s - loss: 0.2177 - acc: 0.924 - ETA: 0s - loss: 0.2178 - acc: 0.924 - ETA: 0s - loss: 0.2179 - acc: 0.924 - ETA: 0s - loss: 0.2174 - acc: 0.924 - ETA: 0s - loss: 0.2185 - acc: 0.924 - ETA: 0s - loss: 0.2191 - acc: 0.924 - ETA: 0s - loss: 0.2193 - acc: 0.923 - ETA: 0s - loss: 0.2194 - acc: 0.923 - ETA: 0s - loss: 0.2181 - acc: 0.924 - 3s 201us/sample - loss: 0.2177 - acc: 0.9247 - val_loss: 0.2976 - val_acc: 0.8801\n",
      "Epoch 19/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - ETA: 2s - loss: 0.2045 - acc: 0.937 - ETA: 2s - loss: 0.2031 - acc: 0.937 - ETA: 2s - loss: 0.2037 - acc: 0.932 - ETA: 2s - loss: 0.2051 - acc: 0.933 - ETA: 2s - loss: 0.2022 - acc: 0.933 - ETA: 2s - loss: 0.1999 - acc: 0.937 - ETA: 1s - loss: 0.2044 - acc: 0.935 - ETA: 1s - loss: 0.2040 - acc: 0.935 - ETA: 1s - loss: 0.2062 - acc: 0.934 - ETA: 1s - loss: 0.2065 - acc: 0.933 - ETA: 1s - loss: 0.2059 - acc: 0.933 - ETA: 1s - loss: 0.2065 - acc: 0.932 - ETA: 1s - loss: 0.2060 - acc: 0.931 - ETA: 1s - loss: 0.2063 - acc: 0.931 - ETA: 1s - loss: 0.2058 - acc: 0.931 - ETA: 1s - loss: 0.2050 - acc: 0.932 - ETA: 1s - loss: 0.2055 - acc: 0.932 - ETA: 0s - loss: 0.2055 - acc: 0.932 - ETA: 0s - loss: 0.2055 - acc: 0.932 - ETA: 0s - loss: 0.2071 - acc: 0.930 - ETA: 0s - loss: 0.2070 - acc: 0.930 - ETA: 0s - loss: 0.2070 - acc: 0.930 - ETA: 0s - loss: 0.2065 - acc: 0.931 - ETA: 0s - loss: 0.2066 - acc: 0.931 - ETA: 0s - loss: 0.2070 - acc: 0.931 - ETA: 0s - loss: 0.2060 - acc: 0.931 - ETA: 0s - loss: 0.2064 - acc: 0.931 - ETA: 0s - loss: 0.2070 - acc: 0.930 - ETA: 0s - loss: 0.2072 - acc: 0.930 - 3s 199us/sample - loss: 0.2074 - acc: 0.9301 - val_loss: 0.2943 - val_acc: 0.8817\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1913 - acc: 0.945 - ETA: 2s - loss: 0.1966 - acc: 0.936 - ETA: 2s - loss: 0.2025 - acc: 0.932 - ETA: 2s - loss: 0.2043 - acc: 0.934 - ETA: 2s - loss: 0.2084 - acc: 0.932 - ETA: 2s - loss: 0.2054 - acc: 0.932 - ETA: 1s - loss: 0.2005 - acc: 0.932 - ETA: 1s - loss: 0.2018 - acc: 0.929 - ETA: 1s - loss: 0.2013 - acc: 0.929 - ETA: 1s - loss: 0.1999 - acc: 0.929 - ETA: 1s - loss: 0.1979 - acc: 0.931 - ETA: 1s - loss: 0.1977 - acc: 0.931 - ETA: 1s - loss: 0.1979 - acc: 0.931 - ETA: 1s - loss: 0.1969 - acc: 0.931 - ETA: 1s - loss: 0.2000 - acc: 0.929 - ETA: 1s - loss: 0.1988 - acc: 0.930 - ETA: 1s - loss: 0.1991 - acc: 0.931 - ETA: 0s - loss: 0.1985 - acc: 0.932 - ETA: 0s - loss: 0.1990 - acc: 0.931 - ETA: 0s - loss: 0.1984 - acc: 0.932 - ETA: 0s - loss: 0.1999 - acc: 0.931 - ETA: 0s - loss: 0.2013 - acc: 0.930 - ETA: 0s - loss: 0.2014 - acc: 0.930 - ETA: 0s - loss: 0.2013 - acc: 0.930 - ETA: 0s - loss: 0.2001 - acc: 0.931 - ETA: 0s - loss: 0.1993 - acc: 0.932 - ETA: 0s - loss: 0.1999 - acc: 0.931 - ETA: 0s - loss: 0.1989 - acc: 0.932 - ETA: 0s - loss: 0.1989 - acc: 0.932 - 3s 181us/sample - loss: 0.1988 - acc: 0.9325 - val_loss: 0.2915 - val_acc: 0.8840\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1917 - acc: 0.945 - ETA: 1s - loss: 0.1873 - acc: 0.948 - ETA: 1s - loss: 0.1845 - acc: 0.943 - ETA: 1s - loss: 0.1866 - acc: 0.939 - ETA: 1s - loss: 0.1855 - acc: 0.939 - ETA: 1s - loss: 0.1870 - acc: 0.937 - ETA: 1s - loss: 0.1846 - acc: 0.938 - ETA: 1s - loss: 0.1839 - acc: 0.938 - ETA: 1s - loss: 0.1842 - acc: 0.938 - ETA: 1s - loss: 0.1849 - acc: 0.938 - ETA: 1s - loss: 0.1855 - acc: 0.938 - ETA: 1s - loss: 0.1846 - acc: 0.938 - ETA: 1s - loss: 0.1850 - acc: 0.938 - ETA: 1s - loss: 0.1855 - acc: 0.937 - ETA: 1s - loss: 0.1870 - acc: 0.936 - ETA: 1s - loss: 0.1862 - acc: 0.937 - ETA: 1s - loss: 0.1862 - acc: 0.937 - ETA: 1s - loss: 0.1875 - acc: 0.936 - ETA: 0s - loss: 0.1881 - acc: 0.936 - ETA: 0s - loss: 0.1897 - acc: 0.936 - ETA: 0s - loss: 0.1904 - acc: 0.935 - ETA: 0s - loss: 0.1904 - acc: 0.936 - ETA: 0s - loss: 0.1900 - acc: 0.936 - ETA: 0s - loss: 0.1900 - acc: 0.936 - ETA: 0s - loss: 0.1905 - acc: 0.936 - ETA: 0s - loss: 0.1901 - acc: 0.936 - ETA: 0s - loss: 0.1894 - acc: 0.937 - ETA: 0s - loss: 0.1898 - acc: 0.937 - ETA: 0s - loss: 0.1899 - acc: 0.936 - 3s 198us/sample - loss: 0.1900 - acc: 0.9366 - val_loss: 0.2901 - val_acc: 0.8839\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1707 - acc: 0.943 - ETA: 2s - loss: 0.1776 - acc: 0.940 - ETA: 2s - loss: 0.1695 - acc: 0.944 - ETA: 1s - loss: 0.1738 - acc: 0.944 - ETA: 1s - loss: 0.1750 - acc: 0.943 - ETA: 1s - loss: 0.1818 - acc: 0.939 - ETA: 1s - loss: 0.1809 - acc: 0.941 - ETA: 1s - loss: 0.1816 - acc: 0.941 - ETA: 1s - loss: 0.1825 - acc: 0.940 - ETA: 1s - loss: 0.1846 - acc: 0.938 - ETA: 1s - loss: 0.1830 - acc: 0.940 - ETA: 1s - loss: 0.1813 - acc: 0.941 - ETA: 1s - loss: 0.1825 - acc: 0.941 - ETA: 1s - loss: 0.1828 - acc: 0.940 - ETA: 1s - loss: 0.1826 - acc: 0.940 - ETA: 1s - loss: 0.1831 - acc: 0.940 - ETA: 1s - loss: 0.1852 - acc: 0.939 - ETA: 0s - loss: 0.1843 - acc: 0.940 - ETA: 0s - loss: 0.1835 - acc: 0.941 - ETA: 0s - loss: 0.1827 - acc: 0.941 - ETA: 0s - loss: 0.1832 - acc: 0.941 - ETA: 0s - loss: 0.1825 - acc: 0.941 - ETA: 0s - loss: 0.1824 - acc: 0.941 - ETA: 0s - loss: 0.1822 - acc: 0.941 - ETA: 0s - loss: 0.1831 - acc: 0.940 - ETA: 0s - loss: 0.1826 - acc: 0.941 - ETA: 0s - loss: 0.1824 - acc: 0.940 - ETA: 0s - loss: 0.1831 - acc: 0.940 - ETA: 0s - loss: 0.1828 - acc: 0.940 - 3s 182us/sample - loss: 0.1825 - acc: 0.9404 - val_loss: 0.2879 - val_acc: 0.8845\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1829 - acc: 0.935 - ETA: 2s - loss: 0.1833 - acc: 0.940 - ETA: 2s - loss: 0.1713 - acc: 0.945 - ETA: 2s - loss: 0.1736 - acc: 0.942 - ETA: 2s - loss: 0.1696 - acc: 0.944 - ETA: 1s - loss: 0.1689 - acc: 0.946 - ETA: 1s - loss: 0.1692 - acc: 0.946 - ETA: 1s - loss: 0.1691 - acc: 0.946 - ETA: 1s - loss: 0.1705 - acc: 0.946 - ETA: 1s - loss: 0.1713 - acc: 0.944 - ETA: 1s - loss: 0.1722 - acc: 0.944 - ETA: 1s - loss: 0.1740 - acc: 0.944 - ETA: 1s - loss: 0.1719 - acc: 0.945 - ETA: 1s - loss: 0.1723 - acc: 0.945 - ETA: 1s - loss: 0.1722 - acc: 0.945 - ETA: 1s - loss: 0.1735 - acc: 0.944 - ETA: 1s - loss: 0.1729 - acc: 0.945 - ETA: 1s - loss: 0.1716 - acc: 0.946 - ETA: 0s - loss: 0.1721 - acc: 0.945 - ETA: 0s - loss: 0.1727 - acc: 0.944 - ETA: 0s - loss: 0.1727 - acc: 0.944 - ETA: 0s - loss: 0.1732 - acc: 0.944 - ETA: 0s - loss: 0.1734 - acc: 0.944 - ETA: 0s - loss: 0.1739 - acc: 0.944 - ETA: 0s - loss: 0.1746 - acc: 0.943 - ETA: 0s - loss: 0.1741 - acc: 0.944 - ETA: 0s - loss: 0.1740 - acc: 0.944 - ETA: 0s - loss: 0.1745 - acc: 0.944 - ETA: 0s - loss: 0.1746 - acc: 0.943 - 3s 195us/sample - loss: 0.1747 - acc: 0.9437 - val_loss: 0.2863 - val_acc: 0.8842\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1498 - acc: 0.953 - ETA: 2s - loss: 0.1543 - acc: 0.948 - ETA: 2s - loss: 0.1646 - acc: 0.940 - ETA: 2s - loss: 0.1662 - acc: 0.941 - ETA: 2s - loss: 0.1689 - acc: 0.942 - ETA: 1s - loss: 0.1755 - acc: 0.940 - ETA: 1s - loss: 0.1719 - acc: 0.944 - ETA: 1s - loss: 0.1707 - acc: 0.944 - ETA: 1s - loss: 0.1723 - acc: 0.942 - ETA: 1s - loss: 0.1726 - acc: 0.943 - ETA: 1s - loss: 0.1733 - acc: 0.942 - ETA: 1s - loss: 0.1718 - acc: 0.944 - ETA: 1s - loss: 0.1723 - acc: 0.943 - ETA: 1s - loss: 0.1721 - acc: 0.943 - ETA: 1s - loss: 0.1721 - acc: 0.943 - ETA: 1s - loss: 0.1718 - acc: 0.943 - ETA: 1s - loss: 0.1711 - acc: 0.944 - ETA: 0s - loss: 0.1704 - acc: 0.944 - ETA: 0s - loss: 0.1709 - acc: 0.944 - ETA: 0s - loss: 0.1709 - acc: 0.944 - ETA: 0s - loss: 0.1697 - acc: 0.945 - ETA: 0s - loss: 0.1709 - acc: 0.944 - ETA: 0s - loss: 0.1696 - acc: 0.945 - ETA: 0s - loss: 0.1698 - acc: 0.945 - ETA: 0s - loss: 0.1686 - acc: 0.945 - ETA: 0s - loss: 0.1682 - acc: 0.945 - ETA: 0s - loss: 0.1676 - acc: 0.946 - ETA: 0s - loss: 0.1681 - acc: 0.946 - ETA: 0s - loss: 0.1678 - acc: 0.946 - 3s 185us/sample - loss: 0.1678 - acc: 0.9465 - val_loss: 0.2865 - val_acc: 0.8838\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1576 - acc: 0.964 - ETA: 2s - loss: 0.1641 - acc: 0.955 - ETA: 2s - loss: 0.1588 - acc: 0.958 - ETA: 2s - loss: 0.1573 - acc: 0.956 - ETA: 2s - loss: 0.1631 - acc: 0.953 - ETA: 2s - loss: 0.1650 - acc: 0.952 - ETA: 2s - loss: 0.1664 - acc: 0.951 - ETA: 1s - loss: 0.1661 - acc: 0.952 - ETA: 1s - loss: 0.1674 - acc: 0.951 - ETA: 1s - loss: 0.1663 - acc: 0.951 - ETA: 1s - loss: 0.1688 - acc: 0.950 - ETA: 1s - loss: 0.1678 - acc: 0.950 - ETA: 1s - loss: 0.1688 - acc: 0.949 - ETA: 1s - loss: 0.1680 - acc: 0.949 - ETA: 1s - loss: 0.1668 - acc: 0.950 - ETA: 1s - loss: 0.1683 - acc: 0.948 - ETA: 1s - loss: 0.1681 - acc: 0.948 - ETA: 1s - loss: 0.1684 - acc: 0.947 - ETA: 0s - loss: 0.1670 - acc: 0.948 - ETA: 0s - loss: 0.1651 - acc: 0.949 - ETA: 0s - loss: 0.1645 - acc: 0.949 - ETA: 0s - loss: 0.1650 - acc: 0.949 - ETA: 0s - loss: 0.1645 - acc: 0.949 - ETA: 0s - loss: 0.1643 - acc: 0.949 - ETA: 0s - loss: 0.1632 - acc: 0.949 - ETA: 0s - loss: 0.1625 - acc: 0.949 - ETA: 0s - loss: 0.1621 - acc: 0.949 - ETA: 0s - loss: 0.1617 - acc: 0.949 - ETA: 0s - loss: 0.1610 - acc: 0.949 - 3s 191us/sample - loss: 0.1613 - acc: 0.9492 - val_loss: 0.2857 - val_acc: 0.8850\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - ETA: 1s - loss: 0.1332 - acc: 0.955 - ETA: 2s - loss: 0.1363 - acc: 0.958 - ETA: 1s - loss: 0.1423 - acc: 0.954 - ETA: 1s - loss: 0.1567 - acc: 0.944 - ETA: 1s - loss: 0.1608 - acc: 0.945 - ETA: 1s - loss: 0.1591 - acc: 0.946 - ETA: 1s - loss: 0.1602 - acc: 0.947 - ETA: 1s - loss: 0.1596 - acc: 0.948 - ETA: 1s - loss: 0.1609 - acc: 0.949 - ETA: 1s - loss: 0.1597 - acc: 0.950 - ETA: 1s - loss: 0.1610 - acc: 0.949 - ETA: 1s - loss: 0.1609 - acc: 0.949 - ETA: 1s - loss: 0.1595 - acc: 0.950 - ETA: 1s - loss: 0.1589 - acc: 0.951 - ETA: 1s - loss: 0.1602 - acc: 0.950 - ETA: 1s - loss: 0.1617 - acc: 0.950 - ETA: 0s - loss: 0.1611 - acc: 0.950 - ETA: 0s - loss: 0.1612 - acc: 0.950 - ETA: 0s - loss: 0.1593 - acc: 0.951 - ETA: 0s - loss: 0.1587 - acc: 0.951 - ETA: 0s - loss: 0.1586 - acc: 0.951 - ETA: 0s - loss: 0.1587 - acc: 0.951 - ETA: 0s - loss: 0.1591 - acc: 0.950 - ETA: 0s - loss: 0.1586 - acc: 0.950 - ETA: 0s - loss: 0.1578 - acc: 0.951 - ETA: 0s - loss: 0.1571 - acc: 0.951 - ETA: 0s - loss: 0.1560 - acc: 0.952 - ETA: 0s - loss: 0.1554 - acc: 0.952 - ETA: 0s - loss: 0.1546 - acc: 0.952 - 3s 177us/sample - loss: 0.1550 - acc: 0.9526 - val_loss: 0.2856 - val_acc: 0.8854\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1289 - acc: 0.964 - ETA: 2s - loss: 0.1425 - acc: 0.957 - ETA: 2s - loss: 0.1413 - acc: 0.957 - ETA: 2s - loss: 0.1422 - acc: 0.958 - ETA: 2s - loss: 0.1416 - acc: 0.958 - ETA: 1s - loss: 0.1442 - acc: 0.957 - ETA: 1s - loss: 0.1456 - acc: 0.957 - ETA: 1s - loss: 0.1473 - acc: 0.956 - ETA: 1s - loss: 0.1479 - acc: 0.955 - ETA: 1s - loss: 0.1461 - acc: 0.957 - ETA: 1s - loss: 0.1438 - acc: 0.958 - ETA: 1s - loss: 0.1422 - acc: 0.957 - ETA: 1s - loss: 0.1429 - acc: 0.957 - ETA: 1s - loss: 0.1465 - acc: 0.957 - ETA: 1s - loss: 0.1485 - acc: 0.956 - ETA: 1s - loss: 0.1491 - acc: 0.956 - ETA: 1s - loss: 0.1477 - acc: 0.956 - ETA: 0s - loss: 0.1472 - acc: 0.957 - ETA: 0s - loss: 0.1471 - acc: 0.957 - ETA: 0s - loss: 0.1475 - acc: 0.956 - ETA: 0s - loss: 0.1474 - acc: 0.956 - ETA: 0s - loss: 0.1474 - acc: 0.956 - ETA: 0s - loss: 0.1470 - acc: 0.957 - ETA: 0s - loss: 0.1469 - acc: 0.957 - ETA: 0s - loss: 0.1476 - acc: 0.956 - ETA: 0s - loss: 0.1491 - acc: 0.955 - ETA: 0s - loss: 0.1493 - acc: 0.955 - ETA: 0s - loss: 0.1489 - acc: 0.955 - ETA: 0s - loss: 0.1491 - acc: 0.955 - 3s 186us/sample - loss: 0.1496 - acc: 0.9553 - val_loss: 0.2870 - val_acc: 0.8834\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1388 - acc: 0.964 - ETA: 2s - loss: 0.1461 - acc: 0.959 - ETA: 2s - loss: 0.1438 - acc: 0.957 - ETA: 2s - loss: 0.1455 - acc: 0.955 - ETA: 2s - loss: 0.1437 - acc: 0.957 - ETA: 2s - loss: 0.1461 - acc: 0.955 - ETA: 1s - loss: 0.1410 - acc: 0.957 - ETA: 1s - loss: 0.1456 - acc: 0.956 - ETA: 1s - loss: 0.1447 - acc: 0.957 - ETA: 1s - loss: 0.1458 - acc: 0.957 - ETA: 1s - loss: 0.1450 - acc: 0.956 - ETA: 1s - loss: 0.1454 - acc: 0.956 - ETA: 1s - loss: 0.1429 - acc: 0.957 - ETA: 1s - loss: 0.1426 - acc: 0.957 - ETA: 1s - loss: 0.1416 - acc: 0.957 - ETA: 1s - loss: 0.1410 - acc: 0.956 - ETA: 1s - loss: 0.1422 - acc: 0.955 - ETA: 0s - loss: 0.1436 - acc: 0.955 - ETA: 0s - loss: 0.1438 - acc: 0.955 - ETA: 0s - loss: 0.1428 - acc: 0.955 - ETA: 0s - loss: 0.1417 - acc: 0.956 - ETA: 0s - loss: 0.1411 - acc: 0.956 - ETA: 0s - loss: 0.1418 - acc: 0.956 - ETA: 0s - loss: 0.1427 - acc: 0.955 - ETA: 0s - loss: 0.1427 - acc: 0.956 - ETA: 0s - loss: 0.1430 - acc: 0.956 - ETA: 0s - loss: 0.1439 - acc: 0.956 - ETA: 0s - loss: 0.1440 - acc: 0.956 - ETA: 0s - loss: 0.1440 - acc: 0.956 - 3s 186us/sample - loss: 0.1439 - acc: 0.9562 - val_loss: 0.2860 - val_acc: 0.8861\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1604 - acc: 0.955 - ETA: 2s - loss: 0.1474 - acc: 0.959 - ETA: 2s - loss: 0.1377 - acc: 0.962 - ETA: 2s - loss: 0.1388 - acc: 0.960 - ETA: 2s - loss: 0.1421 - acc: 0.957 - ETA: 2s - loss: 0.1405 - acc: 0.957 - ETA: 1s - loss: 0.1382 - acc: 0.959 - ETA: 1s - loss: 0.1398 - acc: 0.958 - ETA: 1s - loss: 0.1392 - acc: 0.959 - ETA: 1s - loss: 0.1378 - acc: 0.959 - ETA: 1s - loss: 0.1376 - acc: 0.959 - ETA: 1s - loss: 0.1383 - acc: 0.958 - ETA: 1s - loss: 0.1382 - acc: 0.959 - ETA: 1s - loss: 0.1371 - acc: 0.959 - ETA: 1s - loss: 0.1374 - acc: 0.959 - ETA: 1s - loss: 0.1353 - acc: 0.960 - ETA: 1s - loss: 0.1337 - acc: 0.960 - ETA: 0s - loss: 0.1338 - acc: 0.960 - ETA: 0s - loss: 0.1338 - acc: 0.960 - ETA: 0s - loss: 0.1352 - acc: 0.960 - ETA: 0s - loss: 0.1358 - acc: 0.959 - ETA: 0s - loss: 0.1365 - acc: 0.959 - ETA: 0s - loss: 0.1363 - acc: 0.959 - ETA: 0s - loss: 0.1363 - acc: 0.959 - ETA: 0s - loss: 0.1384 - acc: 0.958 - ETA: 0s - loss: 0.1383 - acc: 0.959 - ETA: 0s - loss: 0.1378 - acc: 0.959 - ETA: 0s - loss: 0.1380 - acc: 0.959 - ETA: 0s - loss: 0.1385 - acc: 0.959 - 3s 182us/sample - loss: 0.1381 - acc: 0.9592 - val_loss: 0.2868 - val_acc: 0.8860\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1652 - acc: 0.941 - ETA: 2s - loss: 0.1567 - acc: 0.947 - ETA: 2s - loss: 0.1435 - acc: 0.953 - ETA: 2s - loss: 0.1413 - acc: 0.955 - ETA: 2s - loss: 0.1410 - acc: 0.955 - ETA: 2s - loss: 0.1420 - acc: 0.955 - ETA: 2s - loss: 0.1420 - acc: 0.956 - ETA: 2s - loss: 0.1413 - acc: 0.956 - ETA: 2s - loss: 0.1397 - acc: 0.957 - ETA: 1s - loss: 0.1370 - acc: 0.959 - ETA: 1s - loss: 0.1374 - acc: 0.959 - ETA: 1s - loss: 0.1377 - acc: 0.959 - ETA: 1s - loss: 0.1365 - acc: 0.959 - ETA: 1s - loss: 0.1372 - acc: 0.959 - ETA: 1s - loss: 0.1388 - acc: 0.959 - ETA: 1s - loss: 0.1367 - acc: 0.959 - ETA: 1s - loss: 0.1386 - acc: 0.959 - ETA: 1s - loss: 0.1381 - acc: 0.959 - ETA: 1s - loss: 0.1392 - acc: 0.959 - ETA: 0s - loss: 0.1374 - acc: 0.960 - ETA: 0s - loss: 0.1370 - acc: 0.960 - ETA: 0s - loss: 0.1358 - acc: 0.960 - ETA: 0s - loss: 0.1369 - acc: 0.960 - ETA: 0s - loss: 0.1360 - acc: 0.960 - ETA: 0s - loss: 0.1362 - acc: 0.960 - ETA: 0s - loss: 0.1356 - acc: 0.960 - ETA: 0s - loss: 0.1345 - acc: 0.960 - ETA: 0s - loss: 0.1340 - acc: 0.960 - ETA: 0s - loss: 0.1330 - acc: 0.961 - 3s 202us/sample - loss: 0.1329 - acc: 0.9614 - val_loss: 0.2879 - val_acc: 0.8869\n",
      "Epoch 31/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1336 - acc: 0.960 - ETA: 2s - loss: 0.1211 - acc: 0.967 - ETA: 1s - loss: 0.1233 - acc: 0.966 - ETA: 1s - loss: 0.1247 - acc: 0.966 - ETA: 1s - loss: 0.1242 - acc: 0.966 - ETA: 1s - loss: 0.1259 - acc: 0.965 - ETA: 1s - loss: 0.1253 - acc: 0.965 - ETA: 1s - loss: 0.1237 - acc: 0.965 - ETA: 1s - loss: 0.1235 - acc: 0.966 - ETA: 1s - loss: 0.1220 - acc: 0.967 - ETA: 1s - loss: 0.1235 - acc: 0.967 - ETA: 1s - loss: 0.1229 - acc: 0.966 - ETA: 1s - loss: 0.1224 - acc: 0.966 - ETA: 1s - loss: 0.1222 - acc: 0.966 - ETA: 1s - loss: 0.1222 - acc: 0.966 - ETA: 1s - loss: 0.1237 - acc: 0.965 - ETA: 1s - loss: 0.1278 - acc: 0.963 - ETA: 0s - loss: 0.1292 - acc: 0.962 - ETA: 0s - loss: 0.1294 - acc: 0.962 - ETA: 0s - loss: 0.1288 - acc: 0.962 - ETA: 0s - loss: 0.1284 - acc: 0.963 - ETA: 0s - loss: 0.1285 - acc: 0.963 - ETA: 0s - loss: 0.1282 - acc: 0.963 - ETA: 0s - loss: 0.1280 - acc: 0.963 - ETA: 0s - loss: 0.1276 - acc: 0.963 - ETA: 0s - loss: 0.1284 - acc: 0.963 - ETA: 0s - loss: 0.1281 - acc: 0.963 - ETA: 0s - loss: 0.1279 - acc: 0.963 - ETA: 0s - loss: 0.1281 - acc: 0.962 - 3s 181us/sample - loss: 0.1278 - acc: 0.9630 - val_loss: 0.2897 - val_acc: 0.8855\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - ETA: 3s - loss: 0.1184 - acc: 0.960 - ETA: 3s - loss: 0.1126 - acc: 0.962 - ETA: 2s - loss: 0.1082 - acc: 0.968 - ETA: 2s - loss: 0.1173 - acc: 0.966 - ETA: 2s - loss: 0.1189 - acc: 0.965 - ETA: 2s - loss: 0.1228 - acc: 0.964 - ETA: 2s - loss: 0.1233 - acc: 0.962 - ETA: 2s - loss: 0.1229 - acc: 0.963 - ETA: 2s - loss: 0.1225 - acc: 0.963 - ETA: 1s - loss: 0.1247 - acc: 0.962 - ETA: 1s - loss: 0.1234 - acc: 0.962 - ETA: 1s - loss: 0.1217 - acc: 0.963 - ETA: 1s - loss: 0.1212 - acc: 0.964 - ETA: 1s - loss: 0.1226 - acc: 0.964 - ETA: 1s - loss: 0.1215 - acc: 0.964 - ETA: 1s - loss: 0.1215 - acc: 0.964 - ETA: 1s - loss: 0.1211 - acc: 0.964 - ETA: 1s - loss: 0.1213 - acc: 0.965 - ETA: 0s - loss: 0.1205 - acc: 0.965 - ETA: 0s - loss: 0.1205 - acc: 0.965 - ETA: 0s - loss: 0.1215 - acc: 0.964 - ETA: 0s - loss: 0.1217 - acc: 0.964 - ETA: 0s - loss: 0.1213 - acc: 0.964 - ETA: 0s - loss: 0.1220 - acc: 0.964 - ETA: 0s - loss: 0.1226 - acc: 0.964 - ETA: 0s - loss: 0.1227 - acc: 0.964 - ETA: 0s - loss: 0.1227 - acc: 0.964 - ETA: 0s - loss: 0.1226 - acc: 0.964 - ETA: 0s - loss: 0.1233 - acc: 0.964 - 3s 186us/sample - loss: 0.1234 - acc: 0.9649 - val_loss: 0.2913 - val_acc: 0.8857\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.0979 - acc: 0.972 - ETA: 2s - loss: 0.1080 - acc: 0.971 - ETA: 2s - loss: 0.1158 - acc: 0.970 - ETA: 2s - loss: 0.1152 - acc: 0.970 - ETA: 2s - loss: 0.1140 - acc: 0.970 - ETA: 1s - loss: 0.1154 - acc: 0.969 - ETA: 1s - loss: 0.1140 - acc: 0.968 - ETA: 1s - loss: 0.1124 - acc: 0.969 - ETA: 1s - loss: 0.1118 - acc: 0.969 - ETA: 1s - loss: 0.1125 - acc: 0.969 - ETA: 1s - loss: 0.1132 - acc: 0.969 - ETA: 1s - loss: 0.1151 - acc: 0.969 - ETA: 1s - loss: 0.1149 - acc: 0.970 - ETA: 1s - loss: 0.1164 - acc: 0.969 - ETA: 1s - loss: 0.1160 - acc: 0.968 - ETA: 1s - loss: 0.1167 - acc: 0.968 - ETA: 0s - loss: 0.1188 - acc: 0.967 - ETA: 0s - loss: 0.1199 - acc: 0.966 - ETA: 0s - loss: 0.1209 - acc: 0.965 - ETA: 0s - loss: 0.1211 - acc: 0.965 - ETA: 0s - loss: 0.1205 - acc: 0.964 - ETA: 0s - loss: 0.1198 - acc: 0.965 - ETA: 0s - loss: 0.1193 - acc: 0.965 - ETA: 0s - loss: 0.1204 - acc: 0.965 - ETA: 0s - loss: 0.1203 - acc: 0.964 - ETA: 0s - loss: 0.1203 - acc: 0.964 - ETA: 0s - loss: 0.1207 - acc: 0.964 - ETA: 0s - loss: 0.1201 - acc: 0.965 - ETA: 0s - loss: 0.1193 - acc: 0.965 - 3s 176us/sample - loss: 0.1192 - acc: 0.9657 - val_loss: 0.2935 - val_acc: 0.8854\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1126 - acc: 0.970 - ETA: 2s - loss: 0.1052 - acc: 0.975 - ETA: 2s - loss: 0.1039 - acc: 0.975 - ETA: 2s - loss: 0.1109 - acc: 0.973 - ETA: 2s - loss: 0.1130 - acc: 0.972 - ETA: 1s - loss: 0.1123 - acc: 0.972 - ETA: 1s - loss: 0.1133 - acc: 0.971 - ETA: 1s - loss: 0.1146 - acc: 0.970 - ETA: 1s - loss: 0.1130 - acc: 0.971 - ETA: 1s - loss: 0.1134 - acc: 0.970 - ETA: 1s - loss: 0.1123 - acc: 0.970 - ETA: 1s - loss: 0.1108 - acc: 0.970 - ETA: 1s - loss: 0.1128 - acc: 0.969 - ETA: 1s - loss: 0.1109 - acc: 0.970 - ETA: 1s - loss: 0.1109 - acc: 0.970 - ETA: 1s - loss: 0.1128 - acc: 0.969 - ETA: 1s - loss: 0.1144 - acc: 0.969 - ETA: 0s - loss: 0.1151 - acc: 0.968 - ETA: 0s - loss: 0.1151 - acc: 0.968 - ETA: 0s - loss: 0.1151 - acc: 0.968 - ETA: 0s - loss: 0.1157 - acc: 0.968 - ETA: 0s - loss: 0.1156 - acc: 0.968 - ETA: 0s - loss: 0.1154 - acc: 0.968 - ETA: 0s - loss: 0.1150 - acc: 0.968 - ETA: 0s - loss: 0.1144 - acc: 0.968 - ETA: 0s - loss: 0.1148 - acc: 0.968 - ETA: 0s - loss: 0.1146 - acc: 0.968 - ETA: 0s - loss: 0.1148 - acc: 0.968 - ETA: 0s - loss: 0.1146 - acc: 0.968 - 3s 187us/sample - loss: 0.1147 - acc: 0.9687 - val_loss: 0.2950 - val_acc: 0.8852\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.1096 - acc: 0.968 - ETA: 2s - loss: 0.1195 - acc: 0.967 - ETA: 2s - loss: 0.1189 - acc: 0.966 - ETA: 2s - loss: 0.1153 - acc: 0.968 - ETA: 2s - loss: 0.1181 - acc: 0.966 - ETA: 1s - loss: 0.1172 - acc: 0.968 - ETA: 1s - loss: 0.1144 - acc: 0.969 - ETA: 1s - loss: 0.1159 - acc: 0.968 - ETA: 1s - loss: 0.1151 - acc: 0.967 - ETA: 1s - loss: 0.1159 - acc: 0.968 - ETA: 1s - loss: 0.1157 - acc: 0.968 - ETA: 1s - loss: 0.1138 - acc: 0.969 - ETA: 1s - loss: 0.1123 - acc: 0.970 - ETA: 1s - loss: 0.1115 - acc: 0.970 - ETA: 1s - loss: 0.1102 - acc: 0.971 - ETA: 1s - loss: 0.1100 - acc: 0.971 - ETA: 1s - loss: 0.1095 - acc: 0.971 - ETA: 0s - loss: 0.1088 - acc: 0.972 - ETA: 0s - loss: 0.1089 - acc: 0.971 - ETA: 0s - loss: 0.1085 - acc: 0.971 - ETA: 0s - loss: 0.1083 - acc: 0.971 - ETA: 0s - loss: 0.1088 - acc: 0.970 - ETA: 0s - loss: 0.1090 - acc: 0.970 - ETA: 0s - loss: 0.1090 - acc: 0.970 - ETA: 0s - loss: 0.1095 - acc: 0.970 - ETA: 0s - loss: 0.1101 - acc: 0.969 - ETA: 0s - loss: 0.1104 - acc: 0.969 - ETA: 0s - loss: 0.1105 - acc: 0.969 - ETA: 0s - loss: 0.1102 - acc: 0.969 - 3s 185us/sample - loss: 0.1103 - acc: 0.9694 - val_loss: 0.2972 - val_acc: 0.8850\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.0960 - acc: 0.970 - ETA: 2s - loss: 0.0992 - acc: 0.971 - ETA: 2s - loss: 0.0989 - acc: 0.972 - ETA: 2s - loss: 0.1041 - acc: 0.969 - ETA: 2s - loss: 0.1031 - acc: 0.969 - ETA: 1s - loss: 0.1022 - acc: 0.971 - ETA: 1s - loss: 0.1030 - acc: 0.970 - ETA: 1s - loss: 0.1058 - acc: 0.970 - ETA: 1s - loss: 0.1054 - acc: 0.970 - ETA: 1s - loss: 0.1072 - acc: 0.969 - ETA: 1s - loss: 0.1057 - acc: 0.970 - ETA: 1s - loss: 0.1052 - acc: 0.970 - ETA: 1s - loss: 0.1044 - acc: 0.970 - ETA: 1s - loss: 0.1051 - acc: 0.970 - ETA: 1s - loss: 0.1058 - acc: 0.970 - ETA: 1s - loss: 0.1067 - acc: 0.969 - ETA: 1s - loss: 0.1052 - acc: 0.970 - ETA: 0s - loss: 0.1058 - acc: 0.969 - ETA: 0s - loss: 0.1065 - acc: 0.969 - ETA: 0s - loss: 0.1068 - acc: 0.969 - ETA: 0s - loss: 0.1061 - acc: 0.970 - ETA: 0s - loss: 0.1065 - acc: 0.970 - ETA: 0s - loss: 0.1065 - acc: 0.970 - ETA: 0s - loss: 0.1065 - acc: 0.970 - ETA: 0s - loss: 0.1068 - acc: 0.970 - ETA: 0s - loss: 0.1075 - acc: 0.970 - ETA: 0s - loss: 0.1068 - acc: 0.970 - ETA: 0s - loss: 0.1064 - acc: 0.970 - ETA: 0s - loss: 0.1064 - acc: 0.970 - 3s 186us/sample - loss: 0.1064 - acc: 0.9708 - val_loss: 0.3003 - val_acc: 0.8836\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - ETA: 2s - loss: 0.0949 - acc: 0.966 - ETA: 2s - loss: 0.1035 - acc: 0.966 - ETA: 2s - loss: 0.1032 - acc: 0.966 - ETA: 2s - loss: 0.1001 - acc: 0.969 - ETA: 2s - loss: 0.1011 - acc: 0.970 - ETA: 1s - loss: 0.1007 - acc: 0.970 - ETA: 1s - loss: 0.1029 - acc: 0.969 - ETA: 1s - loss: 0.1048 - acc: 0.969 - ETA: 1s - loss: 0.1037 - acc: 0.969 - ETA: 1s - loss: 0.1062 - acc: 0.968 - ETA: 1s - loss: 0.1068 - acc: 0.968 - ETA: 1s - loss: 0.1063 - acc: 0.969 - ETA: 1s - loss: 0.1058 - acc: 0.969 - ETA: 1s - loss: 0.1059 - acc: 0.970 - ETA: 1s - loss: 0.1058 - acc: 0.970 - ETA: 1s - loss: 0.1064 - acc: 0.970 - ETA: 1s - loss: 0.1055 - acc: 0.970 - ETA: 1s - loss: 0.1063 - acc: 0.970 - ETA: 0s - loss: 0.1062 - acc: 0.970 - ETA: 0s - loss: 0.1055 - acc: 0.970 - ETA: 0s - loss: 0.1052 - acc: 0.970 - ETA: 0s - loss: 0.1049 - acc: 0.970 - ETA: 0s - loss: 0.1046 - acc: 0.970 - ETA: 0s - loss: 0.1047 - acc: 0.970 - ETA: 0s - loss: 0.1041 - acc: 0.970 - ETA: 0s - loss: 0.1039 - acc: 0.971 - ETA: 0s - loss: 0.1032 - acc: 0.971 - ETA: 0s - loss: 0.1033 - acc: 0.971 - ETA: 0s - loss: 0.1032 - acc: 0.971 - 3s 220us/sample - loss: 0.1031 - acc: 0.9717 - val_loss: 0.3033 - val_acc: 0.8830\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.0990 - acc: 0.972 - ETA: 2s - loss: 0.0911 - acc: 0.976 - ETA: 2s - loss: 0.0982 - acc: 0.972 - ETA: 2s - loss: 0.0985 - acc: 0.973 - ETA: 2s - loss: 0.1000 - acc: 0.973 - ETA: 1s - loss: 0.1023 - acc: 0.971 - ETA: 1s - loss: 0.1005 - acc: 0.971 - ETA: 1s - loss: 0.0997 - acc: 0.972 - ETA: 1s - loss: 0.1009 - acc: 0.972 - ETA: 1s - loss: 0.1017 - acc: 0.972 - ETA: 1s - loss: 0.1023 - acc: 0.973 - ETA: 1s - loss: 0.1013 - acc: 0.974 - ETA: 1s - loss: 0.1005 - acc: 0.974 - ETA: 1s - loss: 0.1008 - acc: 0.973 - ETA: 1s - loss: 0.1012 - acc: 0.973 - ETA: 1s - loss: 0.1008 - acc: 0.973 - ETA: 1s - loss: 0.1004 - acc: 0.974 - ETA: 1s - loss: 0.0998 - acc: 0.974 - ETA: 1s - loss: 0.0991 - acc: 0.974 - ETA: 0s - loss: 0.0981 - acc: 0.974 - ETA: 0s - loss: 0.0984 - acc: 0.974 - ETA: 0s - loss: 0.0976 - acc: 0.975 - ETA: 0s - loss: 0.0979 - acc: 0.974 - ETA: 0s - loss: 0.0982 - acc: 0.974 - ETA: 0s - loss: 0.0989 - acc: 0.974 - ETA: 0s - loss: 0.0986 - acc: 0.974 - ETA: 0s - loss: 0.0985 - acc: 0.974 - ETA: 0s - loss: 0.0983 - acc: 0.974 - ETA: 0s - loss: 0.0988 - acc: 0.973 - 3s 224us/sample - loss: 0.0991 - acc: 0.9738 - val_loss: 0.3054 - val_acc: 0.8832\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.0942 - acc: 0.976 - ETA: 2s - loss: 0.1030 - acc: 0.976 - ETA: 3s - loss: 0.1028 - acc: 0.975 - ETA: 2s - loss: 0.1026 - acc: 0.977 - ETA: 2s - loss: 0.0990 - acc: 0.976 - ETA: 2s - loss: 0.0946 - acc: 0.977 - ETA: 2s - loss: 0.0971 - acc: 0.977 - ETA: 2s - loss: 0.0970 - acc: 0.976 - ETA: 2s - loss: 0.0968 - acc: 0.976 - ETA: 1s - loss: 0.0968 - acc: 0.976 - ETA: 1s - loss: 0.0980 - acc: 0.975 - ETA: 1s - loss: 0.0974 - acc: 0.976 - ETA: 1s - loss: 0.0970 - acc: 0.976 - ETA: 1s - loss: 0.0968 - acc: 0.976 - ETA: 1s - loss: 0.0968 - acc: 0.976 - ETA: 1s - loss: 0.0955 - acc: 0.976 - ETA: 1s - loss: 0.0954 - acc: 0.976 - ETA: 1s - loss: 0.0950 - acc: 0.976 - ETA: 1s - loss: 0.0950 - acc: 0.975 - ETA: 0s - loss: 0.0953 - acc: 0.975 - ETA: 0s - loss: 0.0945 - acc: 0.975 - ETA: 0s - loss: 0.0950 - acc: 0.975 - ETA: 0s - loss: 0.0950 - acc: 0.975 - ETA: 0s - loss: 0.0951 - acc: 0.975 - ETA: 0s - loss: 0.0950 - acc: 0.975 - ETA: 0s - loss: 0.0959 - acc: 0.974 - ETA: 0s - loss: 0.0952 - acc: 0.975 - ETA: 0s - loss: 0.0958 - acc: 0.975 - ETA: 0s - loss: 0.0956 - acc: 0.975 - 3s 215us/sample - loss: 0.0956 - acc: 0.9750 - val_loss: 0.3079 - val_acc: 0.8830\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - ETA: 2s - loss: 0.0981 - acc: 0.974 - ETA: 2s - loss: 0.1039 - acc: 0.969 - ETA: 2s - loss: 0.1027 - acc: 0.972 - ETA: 2s - loss: 0.0965 - acc: 0.973 - ETA: 2s - loss: 0.0942 - acc: 0.975 - ETA: 2s - loss: 0.0927 - acc: 0.976 - ETA: 2s - loss: 0.0898 - acc: 0.978 - ETA: 2s - loss: 0.0907 - acc: 0.978 - ETA: 1s - loss: 0.0922 - acc: 0.977 - ETA: 1s - loss: 0.0916 - acc: 0.977 - ETA: 1s - loss: 0.0914 - acc: 0.978 - ETA: 1s - loss: 0.0911 - acc: 0.978 - ETA: 1s - loss: 0.0920 - acc: 0.977 - ETA: 1s - loss: 0.0933 - acc: 0.977 - ETA: 1s - loss: 0.0918 - acc: 0.977 - ETA: 1s - loss: 0.0914 - acc: 0.977 - ETA: 1s - loss: 0.0922 - acc: 0.977 - ETA: 1s - loss: 0.0917 - acc: 0.977 - ETA: 0s - loss: 0.0920 - acc: 0.977 - ETA: 0s - loss: 0.0917 - acc: 0.977 - ETA: 0s - loss: 0.0921 - acc: 0.977 - ETA: 0s - loss: 0.0915 - acc: 0.977 - ETA: 0s - loss: 0.0914 - acc: 0.976 - ETA: 0s - loss: 0.0911 - acc: 0.977 - ETA: 0s - loss: 0.0919 - acc: 0.976 - ETA: 0s - loss: 0.0922 - acc: 0.976 - ETA: 0s - loss: 0.0918 - acc: 0.976 - ETA: 0s - loss: 0.0923 - acc: 0.976 - ETA: 0s - loss: 0.0922 - acc: 0.976 - 3s 206us/sample - loss: 0.0918 - acc: 0.9763 - val_loss: 0.3111 - val_acc: 0.8825\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - ETA: 8s - loss: 0.2936 - acc: 0.875 - ETA: 2s - loss: 0.3163 - acc: 0.869 - ETA: 2s - loss: 0.2997 - acc: 0.876 - ETA: 2s - loss: 0.3081 - acc: 0.876 - ETA: 2s - loss: 0.3132 - acc: 0.876 - ETA: 2s - loss: 0.3153 - acc: 0.877 - ETA: 2s - loss: 0.3105 - acc: 0.879 - ETA: 2s - loss: 0.3142 - acc: 0.876 - ETA: 2s - loss: 0.3211 - acc: 0.874 - ETA: 2s - loss: 0.3229 - acc: 0.874 - ETA: 2s - loss: 0.3236 - acc: 0.874 - ETA: 2s - loss: 0.3232 - acc: 0.872 - ETA: 2s - loss: 0.3206 - acc: 0.872 - ETA: 2s - loss: 0.3261 - acc: 0.871 - ETA: 1s - loss: 0.3270 - acc: 0.871 - ETA: 1s - loss: 0.3239 - acc: 0.873 - ETA: 1s - loss: 0.3207 - acc: 0.874 - ETA: 1s - loss: 0.3232 - acc: 0.874 - ETA: 1s - loss: 0.3273 - acc: 0.872 - ETA: 1s - loss: 0.3307 - acc: 0.870 - ETA: 1s - loss: 0.3335 - acc: 0.869 - ETA: 1s - loss: 0.3375 - acc: 0.869 - ETA: 1s - loss: 0.3366 - acc: 0.869 - ETA: 1s - loss: 0.3365 - acc: 0.869 - ETA: 1s - loss: 0.3336 - acc: 0.870 - ETA: 1s - loss: 0.3349 - acc: 0.870 - ETA: 1s - loss: 0.3360 - acc: 0.870 - ETA: 1s - loss: 0.3344 - acc: 0.871 - ETA: 1s - loss: 0.3343 - acc: 0.870 - ETA: 1s - loss: 0.3344 - acc: 0.870 - ETA: 1s - loss: 0.3339 - acc: 0.871 - ETA: 1s - loss: 0.3341 - acc: 0.871 - ETA: 1s - loss: 0.3333 - acc: 0.871 - ETA: 1s - loss: 0.3324 - acc: 0.871 - ETA: 1s - loss: 0.3326 - acc: 0.871 - ETA: 1s - loss: 0.3323 - acc: 0.871 - ETA: 1s - loss: 0.3319 - acc: 0.871 - ETA: 1s - loss: 0.3320 - acc: 0.871 - ETA: 0s - loss: 0.3324 - acc: 0.871 - ETA: 0s - loss: 0.3315 - acc: 0.871 - ETA: 0s - loss: 0.3321 - acc: 0.871 - ETA: 0s - loss: 0.3306 - acc: 0.871 - ETA: 0s - loss: 0.3288 - acc: 0.872 - ETA: 0s - loss: 0.3284 - acc: 0.873 - ETA: 0s - loss: 0.3288 - acc: 0.873 - ETA: 0s - loss: 0.3281 - acc: 0.873 - ETA: 0s - loss: 0.3291 - acc: 0.872 - ETA: 0s - loss: 0.3300 - acc: 0.872 - ETA: 0s - loss: 0.3300 - acc: 0.872 - ETA: 0s - loss: 0.3291 - acc: 0.872 - ETA: 0s - loss: 0.3300 - acc: 0.872 - ETA: 0s - loss: 0.3311 - acc: 0.871 - ETA: 0s - loss: 0.3310 - acc: 0.871 - ETA: 0s - loss: 0.3320 - acc: 0.871 - ETA: 0s - loss: 0.3328 - acc: 0.871 - ETA: 0s - loss: 0.3332 - acc: 0.870 - 3s 117us/sample - loss: 0.3323 - acc: 0.8711\n",
      "[0.3323168779659271, 0.87112]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('loss', [0.6753255255063375, 0.6530637384732564, 0.6192547874768575, 0.5767793494860332, 0.5297266829490661, 0.48288914891878765, 0.43944395345052084, 0.4010259724299113, 0.3684559062639872, 0.34089263134002684, 0.31832575971285504, 0.29794745294253033, 0.28092547346750896, 0.26563704216480255, 0.25155585827827454, 0.2390982800324758, 0.2278213806072871, 0.2176586569150289, 0.20740175221761067, 0.19875442547003427, 0.19003191572825115, 0.18249300864537557, 0.17472653814951578, 0.16783838665485382, 0.16130062727928163, 0.15504068706830343, 0.14962983474731445, 0.1438675153573354, 0.13813541933695475, 0.1328749571442604, 0.12784103430112204, 0.12335222373008728, 0.11922425051530203, 0.1146724260409673, 0.11034000882307689, 0.10635087982813517, 0.10313601607879003, 0.09908761161963145, 0.09560657384395599, 0.0917603228410085]), ('acc', [0.7424, 0.76033336, 0.7891333, 0.8099333, 0.8258, 0.8445333, 0.85906667, 0.87226665, 0.88013333, 0.8886, 0.8936, 0.8990667, 0.9036667, 0.90846664, 0.91353333, 0.9182, 0.9208, 0.92466664, 0.93006665, 0.9325333, 0.9366, 0.9404, 0.94373333, 0.9464667, 0.9492, 0.9526, 0.95533335, 0.9562, 0.9592, 0.9614, 0.963, 0.96486664, 0.96566665, 0.9686667, 0.9694, 0.9708, 0.97173333, 0.9738, 0.975, 0.9762667]), ('val_loss', [0.6677737586975098, 0.6415415748596192, 0.6061979365348816, 0.5654175947189332, 0.5214881138801575, 0.4810202332019806, 0.44453957023620605, 0.41431733989715575, 0.389247696018219, 0.36983439741134644, 0.3525445018291473, 0.3399055010795593, 0.32939755206108096, 0.3205702410697937, 0.3132027225494385, 0.30676540150642395, 0.3013737961292267, 0.29761861715316773, 0.2943239678621292, 0.2914899211883545, 0.29005459480285645, 0.2879258264541626, 0.28628959307670593, 0.2864616596221924, 0.2856703365325928, 0.2855588406085968, 0.2869902074337006, 0.2860308711528778, 0.2867520473957062, 0.28787344369888307, 0.28974913210868836, 0.2912879608154297, 0.2935356664657593, 0.2950422651290894, 0.29720252165794375, 0.3002768291473389, 0.303262167596817, 0.3053625030517578, 0.3078545516014099, 0.31107923140525817]), ('val_acc', [0.745, 0.752, 0.7805, 0.8017, 0.8178, 0.832, 0.8431, 0.8501, 0.8584, 0.8609, 0.8684, 0.8715, 0.873, 0.8744, 0.8769, 0.8803, 0.8805, 0.8801, 0.8817, 0.884, 0.8839, 0.8845, 0.8842, 0.8838, 0.885, 0.8854, 0.8834, 0.8861, 0.886, 0.8869, 0.8855, 0.8857, 0.8854, 0.8852, 0.885, 0.8836, 0.883, 0.8832, 0.883, 0.8825])])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''There are four entries: one for each monitored metric during training and validation. We can use these to plot the training and validation loss for comparison, \n",
    "as well as the training and validation accuracy:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
